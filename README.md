## Reseach Paper PDFs


The goal of this repository is to give curious learners one platform to look for some of the most useful research paper, according to me, that I came across or the ones I have heard about. I will be adding my own unnder interpreration of the paper as I get time to make notes of them. Here's a break down according to subject types: 


* Computer Vision
  * [CNN Architecture](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture)
    * [AlexNet](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture/AlexNet)
    * [GoogleLeNet](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture/GoogleLeNet)
    * [Inception](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture/Inception)
    * [MobileNet](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture/MobileNet)
    * [ResNet](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture/ResNet)
    * [VGG-16](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture/VGG-16)
    * [Xception](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture/Xception)
    * [ZFNet](https://github.com/nisargushah/research-paper/tree/main/CNN%20Architecture/ZFnet)
   
  * [Object Detection](https://github.com/nisargushah/research-paper/tree/main/Object%20Detection)
    * [R-CNN](https://github.com/nisargushah/research-paper/tree/main/Object%20Detection/R-CNN)
    * [Fast R-CNN](https://github.com/nisargushah/research-paper/tree/main/Object%20Detection/Fast-RCNN)
    * [Faster R-CNN](https://github.com/nisargushah/research-paper/tree/main/Object%20Detection/Faster%20R-CNN)
    * [Single Shot Multibox Detector (SSD)](https://github.com/nisargushah/research-paper/tree/main/Object%20Detection/SSD)
    * [You Only Look Once (YOLO) ](https://github.com/nisargushah/research-paper/tree/main/Object%20Detection/YOLO)
    * [You Only Look Once (YOLO-9000)](https://github.com/nisargushah/research-paper/tree/main/Object%20Detection/YOLO-9000)
  
  * [Generative Adversarial Network](https://github.com/nisargushah/research-paper/tree/main/Generative%20Adversarial%20Network(GANs))
    * [General Adversarial Network (GANs) ](https://github.com/nisargushah/research-paper/tree/main/Generative%20Adversarial%20Network(GANs)/GANs)
    * [Wasserstein GANs](https://github.com/nisargushah/research-paper/tree/main/Generative%20Adversarial%20Network(GANs)/WGANs)
    * [Deep Convolution GANs](https://github.com/nisargushah/research-paper/blob/main/Generative%20Adversarial%20Network(GANs)/DCGANs)
    * [Pix2Pix](https://github.com/nisargushah/research-paper/tree/main/Generative%20Adversarial%20Network(GANs)/Pix2Pix)
    * [Cycle Consistent GANs](https://github.com/nisargushah/research-paper/tree/main/Generative%20Adversarial%20Network(GANs)/Cycle-Consistent%20GAN)
    
  * [Pose Estimation](https://github.com/nisargushah/research-paper/tree/main/Pose%20Estimation)
  
    * [PoseNet](https://github.com/nisargushah/research-paper/tree/main/Pose%20Estimation/PoseNet)
    * [DensePose](https://github.com/nisargushah/research-paper/tree/main/Pose%20Estimation/DensePose)
    
   
    





## License

All the credit for the research papers should go towards the authors of the respective papers. All of my interpreation is under [MIT License](https://opensource.org/licenses/MIT).

I would like to give all the researchers a shout out for providing excellent quality research.
